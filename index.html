<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Perfume: Lattice Performer (MoveNet + Three.js + Triad)</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #000; font-family: monospace; }
        #canvas-container {
            position: absolute;
            top: 0; left: 0;
            width: 100%; height: 100%;
            z-index: 1;
        }
        #debug-layer {
            position: absolute; top: 0; left: 0;
            width: 100%; height: 100%;
            pointer-events: none; z-index: 2;
        }
        #start-overlay {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: rgba(0,0,0,0.85);
            display: flex; justify-content: center; align-items: center;
            z-index: 10; cursor: pointer;
            transition: opacity 0.5s;
        }
        #start-text {
            color: #88eeee; font-size: 20px; border: 1px solid #88eeee; padding: 20px;
            text-transform: uppercase; letter-spacing: 2px;
            animation: pulseText 2s infinite;
        }
        @keyframes pulseText { 0% { opacity: 0.5; } 50% { opacity: 1; } 100% { opacity: 0.5; } }
        #ui-layer {
            position: absolute; top: 10px; left: 10px;
            color: #88eeee; z-index: 3; pointer-events: none;
            text-shadow: 0 0 5px #88eeee;
            font-size: 12px;
        }
        video { display: none; }
    </style>

    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js",
                "@tweenjs/tween.js": "https://cdn.jsdelivr.net/npm/@tweenjs/tween.js@23.1.1/dist/tween.esm.js"
            }
        }
    </script>
</head>
<body>

    <div id="start-overlay">
        <div id="start-text">Click to Engage System</div>
    </div>

    <div id="ui-layer">
        <div id="status" style="display:none;"></div>
        <div id="metrics" style="display:none; margin-top: 6px; white-space: pre;"></div>
    </div>

    <div id="canvas-container"></div>
    <canvas id="debug-layer"></canvas>
    <video id="video" playsinline></video>

    <!-- Globals for TFJS / Pose-Detection / TWEEN (UMD) -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.15.0/dist/tf-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@4.15.0/dist/tf-converter.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.15.0/dist/tf-backend-webgl.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@2.1.3/dist/pose-detection.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tweenjs/tween.js@23.1.1/dist/tween.umd.js"></script>

    <script type="module">
        import * as THREE from 'three';
        import * as TWEEN from '@tweenjs/tween.js';

        // ============================================================================
        // CONFIGURATION
        // ============================================================================
        /**
         * Global configuration object for the application.
         * Controls camera settings, interaction limits, audio parameters, and visual properties.
         * @constant
         * @type {Object}
         */
        const CONFIG = {
            /** Camera settings */
            camera: { width: 640, height: 480 },
            /** Whether to mirror the video input */
            mirrored: true,
            /** Smoothing factor for pose transitions */
            smoothing: 0.1,
            /** Smoothing factor for depth transitions */
            depthSmoothing: 0.05,
            /** Enable or disable debug mode */
            debug: false,
            /** Grid visual settings */
            grid: {
                size: 10000,
                divisions: 20,
                phaseScale: 500.0
            },
            /** Interaction limits for rotation */
            interaction: {
                maxRoll: Math.PI / 2,
                maxPitch: Math.PI / 6,
                maxYaw: Math.PI / 2
            },
            /** Audio synthesis parameters */
            audio: {
                rootFreq: 73.42, // D2
                detune: 4,
                filterMin: 100,
                filterMax: 8000,
                bpmMin: 40,
                bpmMax: 140,
                lfoRateMin: 0.3,
                lfoRateMax: 8.0
            }
        };

        /**
         * Musical intervals used for harmony generation.
         * Represents frequency ratios relative to the root note.
         * @constant
         * @type {number[]}
         */
        const BEAUTIFUL_INTERVALS = [
            1.0,    // Unison
            1.25,   // Major 3rd
            1.5,    // Perfect 5th
            1.875,  // Major 7th
            2.25,   // Major 9th
            2.8125, // #11
            3.0     // 2 oct + 5th
        ];

        /**
         * Color codes for the performers (Physical, Virtual A, Virtual B).
         * @constant
         * @type {number[]}
         */
        const PERFORMER_COLORS = [
            0x88eeee, // Physical bass
            0xff66ff, // Virtual A
            0xffdd55  // Virtual B
        ];

        // ============================================================================
        // PERFORMER STATE
        // ============================================================================
        /**
         * Manages the state of a single performer (either physical or virtual).
         * Handles position, rotation, and musical properties.
         */
        class PerformerState {
            /**
             * Creates a new PerformerState instance.
             * @param {number|string} colorHex - The color of the performer in hex format.
             * @param {boolean} [isBass=false] - Whether this performer controls the bass voice.
             */
            constructor(colorHex, isBass = false) {
                this.color = new THREE.Color(colorHex);
                this.baseColor = this.color.clone();
                this.isBass = isBass;

                this.hasPerformer = false;
                this.noteRatio = 1.0;

                this.current = {
                    roll: 0,
                    pitch: 0,
                    yaw: 0,
                    depth: -5,
                    phaseZ: 0,
                    bpmPref: 80
                };

                this.target = {
                    roll: 0,
                    pitch: 0,
                    yaw: 0,
                    depth: -5,
                    bpmPref: 80
                };

                this.triangle = {
                    visible: false,
                    v1: new THREE.Vector3(),
                    v2: new THREE.Vector3(),
                    v3: new THREE.Vector3(),
                    area: 0,
                    width: 0.5,
                    height: 0.5
                };
            }

            /**
             * Updates the current physical state by interpolating towards target values.
             * Applies smoothing to roll, pitch, yaw, depth, and BPM.
             */
            updatePhysics() {
                const a = CONFIG.smoothing;
                this.current.roll = THREE.MathUtils.lerp(this.current.roll, this.target.roll, a);
                this.current.pitch = THREE.MathUtils.lerp(this.current.pitch, this.target.pitch, a);
                this.current.yaw = THREE.MathUtils.lerp(this.current.yaw, this.target.yaw, a);
                this.current.depth = THREE.MathUtils.lerp(this.current.depth, this.target.depth, CONFIG.depthSmoothing);
                this.current.phaseZ = this.current.depth * CONFIG.grid.phaseScale;
                this.current.bpmPref = THREE.MathUtils.lerp(this.current.bpmPref, this.target.bpmPref, 0.05);
            }
        }

        // ============================================================================
        // VISION SYSTEM (MoveNet multipose, but currently driving only performer 0)
        // ============================================================================
        /**
         * Handles video input and pose detection using TensorFlow.js MoveNet model.
         */
        class VisionSystem {
            /**
             * Creates a new VisionSystem instance.
             * @param {HTMLVideoElement} videoElement - The HTML video element to use for input.
             */
            constructor(videoElement) {
                this.video = videoElement;
                this.detector = null;
                this.isReady = false;
            }

            /**
             * Initializes the camera and loads the MoveNet model.
             * Requests user media access.
             * @async
             * @returns {Promise<void>}
             * @throws {Error} If getUserMedia is not available.
             */
            async init() {
                let stream;
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    throw new Error("navigator.mediaDevices.getUserMedia not available");
                }
                try {
                    stream = await navigator.mediaDevices.getUserMedia({
                        video: {
                            width: { ideal: CONFIG.camera.width },
                            height: { ideal: CONFIG.camera.height },
                            facingMode: 'user'
                        },
                        audio: false
                    });
                } catch (err) {
                    stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                }
                this.video.srcObject = stream;
                await new Promise(r => {
                    this.video.onloadedmetadata = () => { this.video.play(); r(); };
                });

                if (this.video.videoWidth) {
                    CONFIG.camera.width = this.video.videoWidth;
                    CONFIG.camera.height = this.video.videoHeight;
                }

                await tf.ready();
                this.detector = await poseDetection.createDetector(
                    poseDetection.SupportedModels.MoveNet,
                    {
                        modelType: poseDetection.movenet.modelType.MULTIPOSE_LIGHTNING,
                        enableSmoothing: true,
                        minPoseScore: 0.25
                    }
                );
                this.isReady = true;
            }

            /**
             * Estimates poses from the current video frame.
             * @async
             * @returns {Promise<Array<Object>>} An array of detected poses.
             */
            async update() {
                if (!this.isReady) return [];
                try {
                    return await this.detector.estimatePoses(this.video);
                } catch (e) {
                    return [];
                }
            }
        }

        // ============================================================================
        // LATTICE VIEWPORT (One per Performer)
        // ============================================================================
        /**
         * Manages the 3D scene rendering for a specific performer.
         * Handles the lattice grid and the performer's triangular representation.
         */
        class LatticeViewport {
            /**
             * Creates a new LatticeViewport instance.
             * @param {number|string} colorHex - The primary color for this viewport.
             */
            constructor(colorHex) {
                this.scene = new THREE.Scene();
                this.scene.fog = new THREE.FogExp2(0x000000, 0.0004);

                this.camera = new THREE.PerspectiveCamera(75, 1, 0.1, 15000);
                this.camera.position.set(0, 0, 800);

                this.uniforms = {
                    uTime: { value: 0 },
                    uPhaseZ: { value: 0 },
                    uGridSize: { value: CONFIG.grid.size },
                    uColor: { value: new THREE.Color(colorHex) },
                    uRotation: { value: new THREE.Vector3(0, 0, 0) }
                };

                this.finalPositions = [];
                this.geometry = null;
                this.mesh = null;
                this.triMesh = null;
                this.triWire = null;

                this._initLattice();
                this._initTriangle();
                this._animateInLattice(4000);
            }

            /**
             * Initializes the lattice grid geometry.
             * Creates a BufferGeometry with shader material for the 3D grid.
             * @private
             */
            _initLattice() {
                const size = CONFIG.grid.size;
                const divisions = CONFIG.grid.divisions;
                const step = size / divisions;

                this.finalPositions = [];
                const isLongitudinal = [];

                // X-direction lines
                for (let y = -size / 2; y <= size / 2; y += step) {
                    for (let z = -size / 2; z <= size / 2; z += step) {
                        this.finalPositions.push(-size / 2, y, z, size / 2, y, z);
                        isLongitudinal.push(0, 0);
                    }
                }
                // Y-direction lines
                for (let x = -size / 2; x <= size / 2; x += step) {
                    for (let z = -size / 2; z <= size / 2; z += step) {
                        this.finalPositions.push(x, -size / 2, z, x, size / 2, z);
                        isLongitudinal.push(0, 0);
                    }
                }
                // Z-direction lines
                for (let x = -size / 2; x <= size / 2; x += step) {
                    for (let y = -size / 2; y <= size / 2; y += step) {
                        this.finalPositions.push(x, y, -size / 2, x, y, size / 2);
                        isLongitudinal.push(1, 1);
                    }
                }

                const initial = new Float32Array(this.finalPositions.length).fill(0);
                this.geometry = new THREE.BufferGeometry();
                this.geometry.setAttribute('position', new THREE.BufferAttribute(initial, 3));
                this.geometry.setAttribute('isLongitudinal', new THREE.Float32BufferAttribute(isLongitudinal, 1));

                const material = new THREE.ShaderMaterial({
                    uniforms: this.uniforms,
                    transparent: true,
                    vertexShader: `
                        attribute float isLongitudinal;
                        uniform vec3 uRotation;
                        uniform float uPhaseZ;
                        uniform float uGridSize;
                        varying float vDepth;

                        mat4 rotationMatrix(vec3 axis, float angle) {
                            axis = normalize(axis);
                            float s = sin(angle);
                            float c = cos(angle);
                            float oc = 1.0 - c;
                            return mat4(
                                oc*axis.x*axis.x + c,        oc*axis.x*axis.y - axis.z*s,  oc*axis.z*axis.x + axis.y*s, 0.0,
                                oc*axis.x*axis.y + axis.z*s, oc*axis.y*axis.y + c,        oc*axis.y*axis.z - axis.x*s, 0.0,
                                oc*axis.z*axis.x - axis.y*s, oc*axis.y*axis.z + axis.x*s, oc*axis.z*axis.z + c,        0.0,
                                0.0, 0.0, 0.0, 1.0
                            );
                        }

                        void main() {
                            vec3 pos = position;
                            if (isLongitudinal < 0.5) {
                                float z = pos.z + uPhaseZ;
                                float halfSize = uGridSize * 0.5;
                                z = mod(z + halfSize, uGridSize) - halfSize;
                                pos.z = z;
                            }
                            mat4 rotX = rotationMatrix(vec3(1.0, 0.0, 0.0), uRotation.x);
                            mat4 rotY = rotationMatrix(vec3(0.0, 1.0, 0.0), uRotation.y);
                            mat4 rotZ = rotationMatrix(vec3(0.0, 0.0, 1.0), uRotation.z);
                            mat4 rot = rotZ * rotY * rotX;

                            vec4 mvPosition = modelViewMatrix * rot * vec4(pos, 1.0);
                            gl_Position = projectionMatrix * mvPosition;
                            vDepth = -mvPosition.z;
                        }
                    `,
                    fragmentShader: `
                        uniform vec3 uColor;
                        varying float vDepth;
                        void main() {
                            float fogFactor = exp(-0.0004 * 0.0004 * vDepth * vDepth * 1.44);
                            float alpha = clamp(fogFactor, 0.0, 1.0) * 0.9;
                            gl_FragColor = vec4(uColor, alpha);
                        }
                    `
                });

                this.mesh = new THREE.LineSegments(this.geometry, material);
                this.mesh.frustumCulled = false;
                this.scene.add(this.mesh);
            }

            /**
             * Initializes the triangle mesh used to represent the performer's pose.
             * @private
             */
            _initTriangle() {
                const triGeom = new THREE.BufferGeometry();
                const verts = new Float32Array([
                    0, 0, 0,
                    -100, -100, 0,
                    100, -100, 0
                ]);
                triGeom.setAttribute('position', new THREE.BufferAttribute(verts, 3));

                const triMat = new THREE.MeshBasicMaterial({
                    color: 0xffffff,
                    transparent: true,
                    opacity: 0.12,
                    side: THREE.DoubleSide,
                    depthTest: false
                });

                const wireMat = new THREE.MeshBasicMaterial({
                    color: 0xffffff,
                    wireframe: true,
                    transparent: true,
                    opacity: 0.6,
                    depthTest: false
                });

                this.triMesh = new THREE.Mesh(triGeom, triMat);
                this.triWire = new THREE.Mesh(triGeom, wireMat);
                this.scene.add(this.triMesh);
                this.scene.add(this.triWire);
            }

            /**
             * Animates the lattice grid lines appearing using Tween.js.
             * @private
             * @param {number} [duration=4000] - Duration of the animation in milliseconds.
             */
            _animateInLattice(duration = 4000) {
                const posAttr = this.geometry.getAttribute('position');
                const vertexCount = posAttr.count;
                const finalPos = this.finalPositions;
                const lineCount = vertexCount / 2;
                const indices = Array.from({ length: lineCount }, (_, i) => i);

                for (let i = indices.length - 1; i > 0; i--) {
                    const j = Math.floor(Math.random() * (i + 1));
                    [indices[i], indices[j]] = [indices[j], indices[i]];
                }

                const progress = { value: 0 };

                if (!TWEEN || !TWEEN.Tween) {
                    // If TWEEN ESM not available for some reason, just populate instantly
                    for (let v = 0; v < vertexCount; v++) {
                        posAttr.setXYZ(v,
                            finalPos[v * 3],
                            finalPos[v * 3 + 1],
                            finalPos[v * 3 + 2]
                        );
                    }
                    posAttr.needsUpdate = true;
                    return;
                }

                new TWEEN.Tween(progress)
                    .to({ value: 1 }, duration)
                    .easing(TWEEN.Easing.Exponential.Out)
                    .onUpdate(() => {
                        const currentLines = Math.floor(indices.length * progress.value);
                        for (let i = 0; i < currentLines; i++) {
                            const idx = indices[i];
                            const v1 = idx * 2;
                            const v2 = v1 + 1;
                            posAttr.setXYZ(
                                v1,
                                finalPos[v1 * 3],
                                finalPos[v1 * 3 + 1],
                                finalPos[v1 * 3 + 2]
                            );
                            posAttr.setXYZ(
                                v2,
                                finalPos[v2 * 3],
                                finalPos[v2 * 3 + 1],
                                finalPos[v2 * 3 + 2]
                            );
                        }
                        posAttr.needsUpdate = true;
                    })
                    .start();
            }

            /**
             * Renders the scene for this viewport.
             * Sets the scissor test and viewport area on the renderer.
             * Updates shader uniforms and mesh positions.
             * @param {THREE.WebGLRenderer} renderer - The Three.js renderer.
             * @param {Object} rect - The viewport rectangle {x, y, width, height}.
             * @param {PerformerState} performerState - The state of the performer to render.
             */
            render(renderer, rect, performerState) {
                const { x, y, width, height } = rect;
                renderer.setViewport(x, y, width, height);
                renderer.setScissor(x, y, width, height);
                renderer.setScissorTest(true);

                this.camera.aspect = width / height;
                this.camera.updateProjectionMatrix();

                const now = performance.now() * 0.001;
                this.uniforms.uTime.value = now;
                this.uniforms.uPhaseZ.value = performerState.current.phaseZ;

                const rot = this.uniforms.uRotation.value;
                rot.set(
                    performerState.current.pitch,
                    performerState.current.yaw,
                    performerState.current.roll
                );

                // Color intensity: bright if active, dim if not
                const base = performerState.baseColor;
                const intensity = performerState.hasPerformer ? 1.0 : 0.18;
                this.uniforms.uColor.value.setRGB(
                    base.r * intensity,
                    base.g * intensity,
                    base.b * intensity
                );

                const tri = performerState.triangle;
                if (tri.visible && performerState.hasPerformer) {
                    this.triMesh.visible = true;
                    this.triWire.visible = true;

                    const positions = this.triMesh.geometry.attributes.position.array;
                    const scale = 320;
                    const zOffset = 500;

                    positions[0] = tri.v1.x * scale;
                    positions[1] = tri.v1.y * scale;
                    positions[2] = zOffset;

                    positions[3] = tri.v2.x * scale;
                    positions[4] = tri.v2.y * scale;
                    positions[5] = zOffset;

                    positions[6] = tri.v3.x * scale;
                    positions[7] = tri.v3.y * scale;
                    positions[8] = zOffset;

                    this.triMesh.geometry.attributes.position.needsUpdate = true;
                    this.triWire.geometry.attributes.position.needsUpdate = true;
                } else {
                    this.triMesh.visible = false;
                    this.triWire.visible = false;
                }

                renderer.render(this.scene, this.camera);
            }
        }

        // ============================================================================
        // AUDIO SYSTEM (Triad, one voice per performer)
        // ============================================================================
        /**
         * Manages audio synthesis for the application.
         * Uses the Web Audio API to create voices and effects.
         */
        class AudioSystem {
            /**
             * Creates a new AudioSystem instance.
             */
            constructor() {
                this.ctx = null;
                this.isReady = false;

                this.masterGain = null;
                this.masterPulse = null;
                this.compressor = null;
                this.lfo = null;
                this.lfoGain = null;

                this.voices = [];
            }

            /**
             * Initializes the AudioContext, master effects, and voices.
             * @param {number} voiceCount - The number of voices to create.
             * @async
             * @returns {Promise<void>}
             */
            async init(voiceCount) {
                const AudioContext = window.AudioContext || window.webkitAudioContext;
                this.ctx = new AudioContext();

                this.compressor = this.ctx.createDynamicsCompressor();
                this.compressor.threshold.value = -28;
                this.compressor.knee.value = 24;
                this.compressor.ratio.value = 3;
                this.compressor.attack.value = 0.003;
                this.compressor.release.value = 0.25;

                this.masterPulse = this.ctx.createGain();
                this.masterPulse.gain.value = 0.6;

                this.masterGain = this.ctx.createGain();
                this.masterGain.gain.value = 0.8;

                this.masterPulse.connect(this.masterGain);
                this.masterGain.connect(this.compressor);
                this.compressor.connect(this.ctx.destination);

                this.lfo = this.ctx.createOscillator();
                this.lfo.type = 'sine';
                this.lfo.frequency.value = 0.5;

                this.lfoGain = this.ctx.createGain();
                this.lfoGain.gain.value = 0.4;

                this.lfo.connect(this.lfoGain);
                this.lfoGain.connect(this.masterPulse.gain);
                this.lfo.start();

                this.voices = [];
                for (let i = 0; i < voiceCount; i++) {
                    const v = this._createVoice(i === 0); // voice 0 = bass
                    v.filter.connect(this.masterPulse);
                    this.voices.push(v);
                }

                this.isReady = true;
            }

            /**
             * Creates a single audio voice (synthesizer).
             * @private
             * @param {boolean} isBass - Whether this voice is a bass voice.
             * @returns {Object} The voice object containing oscillators and filters.
             */
            _createVoice(isBass) {
                const v = {};
                v.isBass = isBass;
                v.osc1 = this.ctx.createOscillator();
                v.osc2 = this.ctx.createOscillator();
                v.gain = this.ctx.createGain();
                v.filter = this.ctx.createBiquadFilter();

                v.osc1.type = 'sawtooth';
                v.osc2.type = isBass ? 'sine' : 'triangle';

                v.osc1.frequency.value = CONFIG.audio.rootFreq;
                v.osc2.frequency.value = CONFIG.audio.rootFreq;

                v.osc1.detune.value = CONFIG.audio.detune;
                v.osc2.detune.value = -CONFIG.audio.detune;

                v.gain.gain.value = 0.0;

                v.filter.type = 'lowpass';
                v.filter.Q.value = 1.0;
                v.filter.frequency.value = 400;

                v.osc1.connect(v.gain);
                v.osc2.connect(v.gain);
                v.gain.connect(v.filter);

                v.osc1.start();
                v.osc2.start();

                return v;
            }

            /**
             * Resumes the AudioContext if it is suspended.
             * Essential for starting audio after user interaction.
             */
            resume() {
                if (this.ctx && this.ctx.state === 'suspended') {
                    this.ctx.resume();
                }
            }

            /**
             * Updates audio parameters based on the state of all performers.
             * Modifies frequency, filter cutoff, and gain.
             * @param {PerformerState[]} performers - Array of performer states.
             */
            update(performers) {
                if (!this.isReady) return;
                const now = this.ctx.currentTime;

                // Per-voice mapping
                performers.forEach((p, idx) => {
                    const v = this.voices[idx];
                    if (!v) return;

                    const has = p.hasPerformer;
                    const area = p.triangle.area;
                    const height = THREE.MathUtils.clamp(p.triangle.height, 0, 1);
                    const ratio = p.noteRatio || 1.0;

                    let freq = CONFIG.audio.rootFreq * ratio;
                    if (v.isBass) freq *= 0.5; // one octave down for bass

                    v.osc1.frequency.setTargetAtTime(freq, now, 0.1);
                    v.osc2.frequency.setTargetAtTime(freq, now, 0.1);

                    const cutoff = THREE.MathUtils.lerp(CONFIG.audio.filterMin, CONFIG.audio.filterMax, height);
                    v.filter.frequency.setTargetAtTime(cutoff, now, 0.1);

                    let targetGain = has ? (0.12 + area * 2.4) : 0.0;
                    targetGain = THREE.MathUtils.clamp(targetGain, 0, v.isBass ? 0.9 : 0.6);

                    const timeConst = has ? 0.3 : 1.8;
                    v.gain.gain.setTargetAtTime(targetGain, now, timeConst);
                });

                // Ensemble BPM -> master LFO rate
                let weighted = 0;
                let totalWeight = 0;
                performers.forEach((p, idx) => {
                    if (!p.hasPerformer) return;
                    const weight = idx === 0 ? 2 : 1; // physical performer slightly heavier
                    weighted += p.current.bpmPref * weight;
                    totalWeight += weight;
                });

                const bpm = totalWeight > 0 ? weighted / totalWeight : 60;
                let pulseHz = (bpm / 60) * 0.5; // pulse roughly every 2 beats
                pulseHz = THREE.MathUtils.clamp(pulseHz, CONFIG.audio.lfoRateMin, CONFIG.audio.lfoRateMax);
                this.lfo.frequency.setTargetAtTime(pulseHz, now, 0.3);
            }
        }

        // ============================================================================
        // AUTOPILOT (Virtual performers 1 & 2)
        // ============================================================================
        /**
         * Controls the behavior of virtual performers (autopilot mode).
         * Simulates presence and movement for performers not controlled by a human.
         */
        class Autopilot {
            /**
             * Creates a new Autopilot instance.
             * @param {PerformerState[]} performers - Array of all performer states.
             * @param {number[]} indices - Indices of the performers to control.
             */
            constructor(performers, indices) {
                this.performers = performers;
                this.indices = indices;
                this.nextEventTime = performance.now() + this._randomDelay();
            }

            /**
             * Generates a random delay for the next event.
             * @private
             * @returns {number} Delay in milliseconds.
             */
            _randomDelay() {
                return 3000 + Math.random() * 5000;
            }

            /**
             * Activates a virtual performer with random parameters.
             * @private
             * @param {PerformerState} state - The performer state to modify.
             */
            _turnOn(state) {
                state.hasPerformer = true;
                state.target.bpmPref = THREE.MathUtils.randFloat(CONFIG.audio.bpmMin, CONFIG.audio.bpmMax);

                const idx = Math.floor(Math.random() * BEAUTIFUL_INTERVALS.length);
                state.noteRatio = BEAUTIFUL_INTERVALS[idx];

                const width = THREE.MathUtils.randFloat(0.25, 0.8);
                const height = THREE.MathUtils.randFloat(0.2, 0.9);
                const area = THREE.MathUtils.randFloat(0.15, 0.6);

                state.triangle.width = width;
                state.triangle.height = height;
                state.triangle.area = area;
                state.triangle.visible = true;

                const scale = 0.9;
                state.triangle.v1.set(0, height * scale, 0);
                state.triangle.v2.set(-width * scale, -height * scale, 0);
                state.triangle.v3.set(width * scale, -height * scale, 0);

                state.target.roll = THREE.MathUtils.degToRad(THREE.MathUtils.randFloatSpread(60));
                state.target.pitch = THREE.MathUtils.degToRad(THREE.MathUtils.randFloatSpread(30));
                state.target.yaw = THREE.MathUtils.degToRad(THREE.MathUtils.randFloatSpread(90));
                state.target.depth = THREE.MathUtils.randFloat(-8, -2);
            }

            /**
             * Deactivates a virtual performer.
             * @private
             * @param {PerformerState} state - The performer state to modify.
             */
            _turnOff(state) {
                state.hasPerformer = false;
                state.triangle.visible = false;
                state.target.roll = 0;
                state.target.pitch = 0;
                state.target.yaw = 0;
                state.target.depth = -10;
            }

            /**
             * Executes a single decision step for the autopilot.
             * Randomly turns performers on or off.
             */
            step() {
                const items = this.indices.map(i => ({ idx: i, state: this.performers[i] }));
                const active = items.filter(o => o.state.hasPerformer);
                const activeCount = active.length;

                const chosenIdx = this.indices[Math.floor(Math.random() * this.indices.length)];
                const st = this.performers[chosenIdx];

                if (activeCount === 0) {
                    this._turnOn(st);
                } else if (activeCount === this.indices.length) {
                    if (Math.random() < 0.7) this._turnOff(st);
                    else this._turnOn(st);
                } else {
                    if (st.hasPerformer) {
                        if (Math.random() < 0.5) this._turnOff(st);
                    } else {
                        this._turnOn(st);
                    }
                }
            }

            /**
             * Updates the autopilot state.
             * Checks if enough time has passed to trigger the next step.
             */
            update() {
                const now = performance.now();
                if (now >= this.nextEventTime) {
                    this.step();
                    this.nextEventTime = now + this._randomDelay();
                }
            }
        }

        // ============================================================================
        // DEBUG OVERLAY (Press "D" to toggle)
        // ============================================================================
        /**
         * Manages the debug overlay canvas.
         * Displays performance metrics and internal state when enabled.
         */
        class DebugOverlay {
            /**
             * Creates a new DebugOverlay instance.
             * @param {string} canvasId - The ID of the canvas element.
             */
            constructor(canvasId) {
                this.canvas = document.getElementById(canvasId);
                this.ctx = this.canvas.getContext('2d');
                this.resize();

                window.addEventListener('resize', () => this.resize());
                window.addEventListener('keydown', (e) => {
                    if (e.key === 'd' || e.key === 'D') {
                        CONFIG.debug = !CONFIG.debug;
                    }
                });
            }

            /**
             * Resizes the canvas to match the window dimensions.
             */
            resize() {
                this.canvas.width = window.innerWidth;
                this.canvas.height = window.innerHeight;
            }

            /**
             * Draws debug information to the canvas.
             * @param {Array<Object>} poses - The detected poses.
             * @param {PerformerState[]} performers - Array of performer states.
             */
            draw(poses, performers) {
                this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);

                const statusEl = document.getElementById('status');
                const metricsEl = document.getElementById('metrics');

                if (!CONFIG.debug) {
                    statusEl.style.display = 'none';
                    metricsEl.style.display = 'none';
                    return;
                }

                statusEl.style.display = 'block';
                metricsEl.style.display = 'block';

                statusEl.innerText = performers[0].hasPerformer
                    ? 'TARGET ACQUIRED  (P0: Physical)'
                    : 'SCANNING SECTOR...';

                let text = '';
                performers.forEach((p, idx) => {
                    text += `P${idx} ${p.hasPerformer ? 'ON ' : 'off'}\n`;
                    text += `  depth: ${p.current.depth.toFixed(2)}  bpm: ${p.current.bpmPref.toFixed(1)}\n`;
                    text += `  triA: ${p.triangle.area.toFixed(3)}  W: ${p.triangle.width.toFixed(2)}  H: ${p.triangle.height.toFixed(2)}\n`;
                });
                metricsEl.innerText = text;
            }
        }

        // ============================================================================
        // APP
        // ============================================================================
        /**
         * Main application class.
         * Orchestrates the Vision, Audio, and Rendering systems.
         */
        class App {
            /**
             * Creates a new App instance and initializes the scene.
             */
            constructor() {
                this.vision = new VisionSystem(document.getElementById('video'));

                this.performers = [
                    new PerformerState(PERFORMER_COLORS[0], true),
                    new PerformerState(PERFORMER_COLORS[1], false),
                    new PerformerState(PERFORMER_COLORS[2], false)
                ];

                this.audio = new AudioSystem();
                this.autopilot = new Autopilot(this.performers, [1, 2]);

                this.renderer = new THREE.WebGLRenderer({ antialias: true, alpha: false });
                this.renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
                this.renderer.setSize(window.innerWidth, window.innerHeight);

                document.getElementById('canvas-container').appendChild(this.renderer.domElement);
                window.addEventListener('resize', () => {
                    this.renderer.setSize(window.innerWidth, window.innerHeight);
                });

                this.viewports = this.performers.map(
                    p => new LatticeViewport(p.color.getHex())
                );

                this.debug = new DebugOverlay('debug-layer');

                this._wireAudioStartOverlay();
                this._init();
            }

            /**
             * Sets up the start overlay to initialize audio on user interaction.
             * @private
             */
            _wireAudioStartOverlay() {
                const overlay = document.getElementById('start-overlay');
                overlay.addEventListener('click', async () => {
                    await this.audio.init(this.performers.length);
                    this.audio.resume();
                    overlay.style.opacity = 0;
                    setTimeout(() => overlay.style.display = 'none', 500);
                }, { once: true });
            }

            /**
             * Initializes the vision system and starts the main loop.
             * @private
             * @async
             */
            async _init() {
                try {
                    await this.vision.init();
                } catch (err) {
                    console.error('Vision init failed:', err);
                }
                this.loop();
            }

            /**
             * Maps detected poses to the physical performer's state.
             * Calculates rotation, depth, and musical parameters from keypoints.
             * @private
             * @param {Array<Object>} poses - Array of detected poses from MoveNet.
             */
            _updatePhysicalFromPoses(poses) {
                const p = this.performers[0];
                const vW = CONFIG.camera.width;
                const vH = CONFIG.camera.height;

                if (!poses || poses.length === 0) {
                    p.hasPerformer = false;
                    p.triangle.visible = false;
                    p.target.roll = 0;
                    p.target.pitch = 0;
                    p.target.yaw = 0;
                    p.target.depth = -10;
                    return;
                }

                let dominant = null;
                let maxWidth = 0;
                for (const pose of poses) {
                    const ls = pose.keypoints.find(k => k.name === 'left_shoulder');
                    const rs = pose.keypoints.find(k => k.name === 'right_shoulder');
                    if (ls && rs && ls.score > 0.3 && rs.score > 0.3) {
                        const w = Math.hypot(rs.x - ls.x, rs.y - ls.y);
                        if (w > maxWidth) {
                            maxWidth = w;
                            dominant = { pose, width: w, ls, rs };
                        }
                    }
                }

                if (!dominant) {
                    p.hasPerformer = false;
                    p.triangle.visible = false;
                    p.target.roll = 0;
                    p.target.pitch = 0;
                    p.target.yaw = 0;
                    p.target.depth = -10;
                    return;
                }

                p.hasPerformer = true;

                const { pose, width, ls, rs } = dominant;

                // Yaw from shoulder tilt
                const dy = rs.y - ls.y;
                let tiltSignal = -dy / width;
                if (!CONFIG.mirrored) tiltSignal *= -1;
                p.target.yaw = tiltSignal * CONFIG.interaction.maxYaw * 2.5;

                // Pitch from vertical position
                const cy = (ls.y + rs.y) / 2;
                let ny = (cy / vH) * 2 - 1;
                p.target.pitch = -ny * CONFIG.interaction.maxPitch;

                // Depth from torso box if hips are available, otherwise shoulder span
                const lHip = pose.keypoints.find(k => k.name === 'left_hip');
                const rHip = pose.keypoints.find(k => k.name === 'right_hip');
                let normMetric = 0;
                if (lHip && rHip && lHip.score > 0.3 && rHip.score > 0.3) {
                    const mxS = (ls.x + rs.x) / 2;
                    const myS = (ls.y + rs.y) / 2;
                    const mxH = (lHip.x + rHip.x) / 2;
                    const myH = (lHip.y + rHip.y) / 2;
                    normMetric = Math.hypot(mxS - mxH, myS - myH) / vH;
                } else {
                    normMetric = width / vW;
                }
                const safeMetric = Math.max(0.05, normMetric);
                p.target.depth = -(1.0 / safeMetric);

                // Wrists / triangle
                const lWrist = pose.keypoints.find(k => k.name === 'left_wrist');
                const rWrist = pose.keypoints.find(k => k.name === 'right_wrist');

                if (lWrist && rWrist && lWrist.score > 0.3 && rWrist.score > 0.3) {
                    p.triangle.visible = true;

                    const nx = (ls.x + rs.x) / 2;
                    const nyNeck = (ls.y + rs.y) / 2;

                    const mapX = (val) => (val / vW) * 2 - 1;
                    const mapY = (val) => -((val / vH) * 2 - 1);

                    const xMult = CONFIG.mirrored ? -1 : 1;

                    p.triangle.v1.set(mapX(nx) * xMult, mapY(nyNeck), 0);
                    p.triangle.v2.set(mapX(lWrist.x) * xMult, mapY(lWrist.y), 0);
                    p.triangle.v3.set(mapX(rWrist.x) * xMult, mapY(rWrist.y), 0);

                    const handDist = Math.hypot(lWrist.x - rWrist.x, lWrist.y - rWrist.y);
                    p.triangle.width = handDist / vW;

                    const avgHandY = (lWrist.y + rWrist.y) / 2;
                    p.triangle.height = 1.0 - (avgHandY / vH);

                    const tArea = 0.5 * Math.abs(
                        lWrist.x * (rWrist.y - nyNeck) +
                        rWrist.x * (nyNeck - lWrist.y) +
                        nx * (lWrist.y - rWrist.y)
                    );
                    p.triangle.area = tArea / (vW * vH);

                    const dx = lWrist.x - rWrist.x;
                    const dyH = lWrist.y - rWrist.y;
                    let handAngle = Math.atan2(dyH, dx);
                    if (CONFIG.mirrored) handAngle *= -1;
                    p.target.roll = handAngle;
                } else {
                    p.triangle.visible = false;
                    p.triangle.area = 0;
                    p.triangle.width = 0.5;
                    p.triangle.height = 0.5;
                    p.target.roll = 0;
                }

                // Map triangle to BPM + interval
                const w = THREE.MathUtils.clamp(p.triangle.width, 0, 1);
                const h = THREE.MathUtils.clamp(p.triangle.height, 0, 1);

                const bpm = THREE.MathUtils.lerp(CONFIG.audio.bpmMax, CONFIG.audio.bpmMin, w);
                p.target.bpmPref = bpm;

                const idx = Math.floor(h * BEAUTIFUL_INTERVALS.length);
                const safeIdx = Math.min(BEAUTIFUL_INTERVALS.length - 1, Math.max(0, idx));
                p.noteRatio = BEAUTIFUL_INTERVALS[safeIdx];
            }

            /**
             * Renders all active viewports to the screen.
             * Divides the screen into vertical strips for each performer.
             * @private
             */
            _renderViewports() {
                const width = window.innerWidth;
                const height = window.innerHeight;

                this.renderer.setSize(width, height);
                this.renderer.setScissorTest(true);

                const activeIndices = this.performers
                    .map((p, idx) => ({ p, idx }))
                    .filter(o => o.p.hasPerformer);

                let indicesToRender;
                if (activeIndices.length === 0) {
                    indicesToRender = [0];
                } else {
                    indicesToRender = activeIndices.map(o => o.idx);
                }

                const count = indicesToRender.length;
                const viewportWidth = width / count;

                indicesToRender.forEach((idx, order) => {
                    const rect = {
                        x: order * viewportWidth,
                        y: 0,
                        width: viewportWidth,
                        height
                    };
                    this.viewports[idx].render(this.renderer, rect, this.performers[idx]);
                });
            }

            /**
             * The main game loop.
             * Updates vision, physics, audio, and renders the scene.
             * Requests the next animation frame.
             * @async
             */
            async loop() {
                const poses = await this.vision.update();

                this._updatePhysicalFromPoses(poses);
                this.autopilot.update();

                this.performers.forEach(p => p.updatePhysics());

                if (this.audio.isReady) {
                    this.audio.update(this.performers);
                }

                TWEEN.update();
                this._renderViewports();
                this.debug.draw(poses, this.performers);

                requestAnimationFrame(() => this.loop());
            }
        }

        window.onload = () => {
            new App();
        };
    </script>
</body>
</html>
